{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.table import Table, join, Column\n",
    "\n",
    "from astropy.io import ascii\n",
    "import glob, re\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "\n",
    "mpl.style.use('seaborn-colorblind')\n",
    "\n",
    "#To make sure we have always the same matplotlib settings\n",
    "#(the ones in comments are the ipython notebook settings)\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(12.0,9.0)    #(6.0,4.0)\n",
    "mpl.rcParams['font.size']=18               #10 \n",
    "mpl.rcParams['savefig.dpi']= 200             #72 \n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "colours = mpl.rcParams['axes.prop_cycle'].by_key()['color']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook reads in Keith's abundances and Guy's asteroseismology to produce the tables for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_diff = \"../data/abundances/Pope_abundances_diff_arcturus.fits\"\n",
    "fname_diff = \"../data/abundtable_ref.fits\"\n",
    "fname_nodiff = \"../data/abundances/Pope_abundances_nodiff.fits\"\n",
    "fname_diff = \"../data/abundtable.fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = Table.read(fname_diff)\n",
    "diff.rename_column('Star','Object')\n",
    "diff.sort('Object')\n",
    "nodiff = Table.read(fname_nodiff)\n",
    "nodiff.sort('Object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do abundances compare between the differential and non-differential methods? Not too badly. Many more elements lack differential abundances than absolute abundances so it looks like in the paper we shouldn't use the differential. Good to include in online data though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j, key in enumerate(diff.keys()[1:]):\n",
    "#     if key[0]=='e':\n",
    "#         continue\n",
    "#     plt.figure(j)\n",
    "#     plt.plot(diff[key],nodiff[key],'.')\n",
    "#     plt.title(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Object',\n",
       " 'Ca_Fe',\n",
       " 'eCa_Fe',\n",
       " 'Mg_Fe',\n",
       " 'eMg_Fe',\n",
       " 'Si_Fe',\n",
       " 'eSi_Fe',\n",
       " 'Ti_Fe',\n",
       " 'eTi_Fe',\n",
       " 'O_Fe',\n",
       " 'eO_Fe',\n",
       " 'Al_Fe',\n",
       " 'eAl_Fe',\n",
       " 'Ba_Fe',\n",
       " 'eBa_Fe',\n",
       " 'Na_Fe',\n",
       " 'eNa_Fe',\n",
       " 'Ni_Fe',\n",
       " 'eNi_Fe',\n",
       " 'Mn_Fe',\n",
       " 'eMn_Fe',\n",
       " 'Co_Fe',\n",
       " 'eCo_Fe',\n",
       " 'Eu_Fe',\n",
       " 'eEu_Fe',\n",
       " 'La_Fe',\n",
       " 'eLa_Fe',\n",
       " 'Zr_Fe',\n",
       " 'eZr_Fe',\n",
       " 'Sr_Fe',\n",
       " 'eSr_Fe',\n",
       " 'Zn_Fe',\n",
       " 'eZn_Fe',\n",
       " 'Y_Fe',\n",
       " 'eY_Fe',\n",
       " 'Cr_Fe',\n",
       " 'eCr_Fe',\n",
       " 'V_Fe',\n",
       " 'eV_Fe',\n",
       " 'Cu_Fe',\n",
       " 'eCu_Fe',\n",
       " 'Sc_Fe',\n",
       " 'eSc_Fe']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodiff.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = filter(lambda x: x[0]!='e', nodiff.keys()[1:])\n",
    "# print elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ca_Fe',\n",
       " 'Mg_Fe',\n",
       " 'Si_Fe',\n",
       " 'Ti_Fe',\n",
       " 'O_Fe',\n",
       " 'Al_Fe',\n",
       " 'Ba_Fe',\n",
       " 'Na_Fe',\n",
       " 'Ni_Fe',\n",
       " 'Mn_Fe',\n",
       " 'Co_Fe',\n",
       " 'Eu_Fe',\n",
       " 'La_Fe',\n",
       " 'Zr_Fe',\n",
       " 'Sr_Fe',\n",
       " 'Zn_Fe',\n",
       " 'Y_Fe',\n",
       " 'Cr_Fe',\n",
       " 'V_Fe',\n",
       " 'Cu_Fe',\n",
       " 'Sc_Fe']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a string-formatted table merging abundances with their uncertainties appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ['Mg','Ti','Si','Ca','Al','V','Ni']\n",
    "neutron = ['Sr','Y','Zr','Ba','La','Eu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sr\n",
      "Y\n",
      "Zr\n",
      "Ba\n",
      "La\n",
      "Eu\n"
     ]
    }
   ],
   "source": [
    "for ell in neutron:\n",
    "    print ell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtab = Table([Column([str(obj).replace('_',' ') for obj in diff['Object']],name='Object')])\n",
    "\n",
    "# first do the differential elements\n",
    "\n",
    "for el in alpha:\n",
    "    col = diff[el]\n",
    "    ecol = diff['%serr' % el]\n",
    "    test = Column(['--' if 'nan' in str(col[j]) else '$%.2f \\pm %.2f$' % (float(col[j]),float(ecol[j])) for j, x in enumerate(col)],name='[%s/Fe]' % el.replace('_Fe',''))\n",
    "#     test = Column(['$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=el.replace('_Fe',''))\n",
    "    newtab.add_column(test)\n",
    "    \n",
    "#     print el\n",
    "\n",
    "# Then do the neutron capture elements\n",
    "newtab2 = Table([Column([str(obj).replace('_',' ') for obj in nodiff['Object']],name='Object')])\n",
    "\n",
    "for ell in neutron:\n",
    "    el = '%s_Fe' % ell\n",
    "    col = nodiff[el]\n",
    "    ecol = nodiff['e%s' % el]\n",
    "    test = Column(['--' if 'nan' in str(col[j]) else '$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name='[%s/Fe]' % el.replace('_Fe',''))\n",
    "#     test = Column(['$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=el.replace('_Fe',''))\n",
    "\n",
    "    newtab2.add_column(test)\n",
    "    \n",
    "# newtab3 = Table([Column([str(obj).replace('_',' ') for obj in nodiff['Object']],name='Object')])\n",
    "\n",
    "# for el in elements[15:]:\n",
    "#     col = nodiff[el]\n",
    "#     ecol = nodiff['e%s' % el]\n",
    "#     test = Column(['--' if 'nan' in str(col[j]) else '$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name='[%s/Fe]' % el.replace('_Fe',''))\n",
    "# #     test = Column(['$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=el.replace('_Fe',''))\n",
    "\n",
    "#     newtab3.add_column(test)\n",
    "\n",
    "    \n",
    "# newtab_diff = Table([diff['Object']])\n",
    "\n",
    "# for el in elements:\n",
    "#     col = diff[el]\n",
    "#     ecol = diff['e%s' % el]\n",
    "#     test = Column(['--' if 'nan' in str(col[j]) else '%.2f $\\pm$ %.2f' % (col[j],ecol[j]) for j, x in enumerate(col)],name=el.replace('_Fe',''))\n",
    "# #     test = Column(['$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=el.replace('_Fe',''))\n",
    "\n",
    "#     newtab_diff.add_column(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oxford_join(string_list):\n",
    "    '''From https://stackoverflow.com/questions/19838976/grammatical-list-join-in-python'''\n",
    "    if len(string_list) < 1:\n",
    "        text = ''\n",
    "    elif len(string_list) == 1:\n",
    "        text = string_list[0]\n",
    "    elif len(string_list) == 2:\n",
    "        text = ' and '.join(string_list)\n",
    "    else:\n",
    "        text = ', '.join(string_list)\n",
    "        text = '{parts[0]}, and {parts[2]}'.format(parts=text.rpartition(', '))  # oxford comma\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now produce three LaTeX tables to go into the paper directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: ../paper/abundances_1.tex already exists. Automatically overwriting ASCII files is deprecated. Use the argument 'overwrite=True' in the future. [astropy.io.ascii.ui]\n",
      "WARNING: AstropyDeprecationWarning: ../paper/abundances_2.tex already exists. Automatically overwriting ASCII files is deprecated. Use the argument 'overwrite=True' in the future. [astropy.io.ascii.ui]\n"
     ]
    }
   ],
   "source": [
    "latexdict = ascii.latex.latexdicts['AA'].copy()\n",
    "latexdict['tabletype']= 'table*'\n",
    "\n",
    "caption1 = r'Chemical abundances relative to iron for stars in the red giant sample as determined by BACCHUS,  differential line-by-line comparison to Arcturus, as described in Section~\\ref{spectroscopy}, for the elements %s. Dashes indicate elements for which abundances could not be reliably computed.' % oxford_join([el.replace('_Fe','') for el in filter(lambda x: x !='O_Fe',elements[0:8])])\n",
    "caption2 = r'Chemical abundances relative to iron of neutron capture elements for stars in the red giant sample as determined by BACCHUS, without differential line-by-line comparison to Arcturus, as described in Section~\\ref{spectroscopy}, for the elements %s. Dashes indicate elements for which abundances could not be reliably computed.' % oxford_join([el.replace('_Fe','') for el in elements[8:15]])\n",
    "# caption3 = r'Chemical abundances relative to iron for stars in the red giant sample as determined by BACCHUS, without differential line-by-line comparison to Arcturus, as described in Section~\\ref{spectroscopy}, for the elements %s. Dashes indicate elements for which abundances could not be reliably computed.' % oxford_join([el.replace('_Fe','') for el in elements[15:]])\n",
    "\n",
    "caption1 = caption1+r'The catalogue of abundances for neutron capture elements continues in Table~\\ref{elems2}.'\n",
    "# caption2 = caption2+r'The catalogue of abundances for more elements continues in Table~\\ref{elems3}.'\n",
    "\n",
    "\n",
    "newtab.write('../paper/abundances_1.tex',format='latex',latexdict=latexdict,caption=caption1+'\\label{elems1}')\n",
    "newtab2.write('../paper/abundances_2.tex',format='latex',latexdict=latexdict,caption=caption2+'\\label{elems2}')\n",
    "# newtab3.write('../paper/abundances_3.tex',format='latex',latexdict=latexdict,caption=caption3+'\\label{elems3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's also do the stellar properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_merged =\"../data/abundances/final_pope_merged.fits\"\n",
    "fname_merged = '../data/spc_final.txt'\n",
    "fname_mass = '../data/smeartest201018_SeismoFullove02_full_notefftol.ascii'\n",
    "merged = Table.read(fname_merged,format='ascii')\n",
    "masses = Table.read(fname_mass,format='ascii')\n",
    "masses['age'] /= 1000. # Gyr not Myr\n",
    "masses['age_errp'] /= 1000.\n",
    "masses['age_errm'] /= 1000.\n",
    "\n",
    "# fname_spc = \"../data/spc_final.txt\"\n",
    "# spc = Table.read(fname_spc,format='ascii')\n",
    "astero_logg = Table.read('../data/pope_asteroseismology.csv')\n",
    "# merged = Table.read(fname_merged)\n",
    "merged.rename_column('RVerr','RV_err')\n",
    "merged.keys()\n",
    "merged.sort('Object')\n",
    "joint = join(merged,astero_logg,keys='Object')\n",
    "joint = join(joint,masses,keys='Object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Object',\n",
       " 'massfin',\n",
       " 'massfin_errp',\n",
       " 'massfin_errm',\n",
       " 'radPhot',\n",
       " 'radPhot_errp',\n",
       " 'radPhot_errm',\n",
       " 'logg',\n",
       " 'logg_errp',\n",
       " 'logg_errm',\n",
       " 'age',\n",
       " 'age_errp',\n",
       " 'age_errm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masses.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "counter2 = []\n",
    "for obj in merged['Object']:\n",
    "    if obj not in astero_logg['Object']:\n",
    "#         print obj\n",
    "        counter.append(obj)\n",
    "for obj in astero_logg['Object']:\n",
    "    if obj not in merged['Object']:\n",
    "#         print obj\n",
    "        counter2.append(obj)\n",
    "\n",
    "# print len(counter)\n",
    "# print len(counter2)\n",
    "# print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, obj in enumerate(astero_logg['Object']):\n",
    "    ind = merged['Object']==obj\n",
    "    merged[ind]['log_g'] = astero_logg['log_g'][j]\n",
    "    merged[ind]['log_g_err'] = astero_logg['log_g_err'][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtab = Table([Column([str(obj).replace('_',' ') for obj in joint['Object']],name='Object')])\n",
    "\n",
    "newkeys = ['RV', 'Teff', 'log_g', 'monh','vsini','SNRe']\n",
    "names = [r'RV',r'\\teff', r'\\logg',r'[M/H]',r'$V\\sin{i}$',r'SNR']\n",
    "units = [r'(km/s)', r'(K)', '','','(km/s)','']\n",
    "\n",
    "for k, key in enumerate(newkeys):\n",
    "    col = joint[key]\n",
    "    if key+'_err' in joint.keys():\n",
    "        ecol = joint['%s_err' % key]\n",
    "        if 'Teff' in key:\n",
    "            test = Column(['--' if 'nan' in str(col[j]) else '$%.0f \\pm %.0f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "        else:\n",
    "            test = Column(['--' if 'nan' in str(col[j]) else '$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "    else:\n",
    "        test = Column(['%.1f' % (col[j]) for j, x in enumerate(col)],name=names[k])\n",
    "    \n",
    "    newtab.add_column(test)\n",
    "    \n",
    "amaliekeys = ['massfin','radPhot','age']\n",
    "amalienames = ['Mass', 'Radius','Age']\n",
    "amalieunits = ['(\\msun)','(\\\\rsun)','(Gyr)']\n",
    "\n",
    "for k, key in enumerate(amaliekeys):\n",
    "    col = joint[key]\n",
    "    ecolp = joint['%s_errp' % key]\n",
    "    ecolm = joint['%s_errm' % key]\n",
    "    test = Column(['--' if 'nan' in str(col[j]) else '$%.2f^{+%.2f}_{-%.2f}$' % (col[j],ecolp[j],ecolm[j]) for j, x in enumerate(col)],name=amalienames[k])\n",
    "    \n",
    "    newtab.add_column(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(\\\\msun)', '(\\\\rsun)', '(Gyr)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amalieunits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "latexdict = ascii.latex.latexdicts['AA'].copy()\n",
    "latexdict['tabletype']= 'table*'\n",
    "latexdict['units'] = dict(zip(names+amalienames,units+amalieunits))\n",
    "\n",
    "caption = r'Fundamental stellar parameters for the red giant sample as determined jointly by asteroseismology (asteroseismic \\logg; Section~\\ref{asteroseismology}) and spectroscopy (%s; Section~\\ref{spectroscopy}.)' % oxford_join(names+amalienames)  \n",
    "caption = caption+r'\\label{stellar_props}'\n",
    "newtab.write('../paper/stellar_props.tex',format='latex',latexdict=latexdict,caption=caption+'\\label{stellar_props}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's look at the proper spectroscopy with Dnu measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_seismic = \"../data/smear_Dnu.csv\"\n",
    "seismic = Table.read(fname_seismic)\n",
    "seismic.remove_row(np.where(seismic['Star_ID']=='HD_189636')[0][0])\n",
    "seismic.sort('Star_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtab = Table([Column([str(obj).replace('_',' ') for obj in seismic['Star_ID']],name='Object')])\n",
    "\n",
    "newkeys = ['Dnu', 'Numax', 'eps']\n",
    "names = [r'\\Dnu',r'\\numax', r'$\\epsilon$']\n",
    "units = [r'(\\muHz)', r'(\\muHz)','']\n",
    "\n",
    "for k, key in enumerate(newkeys):\n",
    "    col = seismic[key]\n",
    "    if key+'_err' in seismic.keys():\n",
    "        ecol = seismic['%s_err' % key]\n",
    "        if 'Teff' in key:\n",
    "            test = Column(['--' if 'nan' in str(col[j]) else '$%.0f \\pm %.0f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "        else:\n",
    "            test = Column(['--' if 'nan' in str(col[j]) else '$%.2f \\pm %.2f$' % (col[j],ecol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "    else:\n",
    "        test = Column(['%.1f' % (col[j]) for j, x in enumerate(col)],name=names[k])\n",
    "    \n",
    "    newtab.add_column(test)\n",
    "\n",
    "latexdict = ascii.latex.latexdicts['AA'].copy()\n",
    "latexdict['tabletype']= 'table'\n",
    "latexdict['units'] = dict(zip(names,units))\n",
    "\n",
    "caption = r'Global asteroseismic parameters %s for the red giant sample as discussed in Section~\\ref{asteroseismology}.' % oxford_join(names)  \n",
    "caption = caption+r'\\label{astero_table}'\n",
    "newtab.write('../paper/astero_table.tex',format='latex',latexdict=latexdict,caption=caption+'\\label{stellar_props}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on individual stars from Guy Davies\n",
    "\n",
    "BD+39_388 - No secure detection.\n",
    "\n",
    "BD+43_306 - Big peaks but not consistent enough with RG pattern.\n",
    "\n",
    "HD_179959 - Pattern is too complicated - is this two stars??  Literature says no.\n",
    "\n",
    "HD_185351 - Odd mode envelope - No explanation.\n",
    "\n",
    "HD_187217 - No info on this star - maybe a double but very difficult to tell.\n",
    "\n",
    "HD_188639 - Too difficult to get a robust Dnu.\n",
    "\n",
    "HD_188875 -  Too difficult to get a robust Dnu.\n",
    "\n",
    "HD_188629 - Too difficult to get a robust Dnu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the stars follow the expected numax-Dnu relation\n",
    "plt.errorbar(seismic['Numax'],seismic['Dnu'],xerr=seismic['Numax_err'],yerr=seismic['Dnu_err'],linestyle='none')\n",
    "plt.xlabel(r'$\\nu_{max}$ ($\\mu$Hz)')\n",
    "plt.ylabel(r'$\\Delta\\nu$ ($\\mu$Hz)')\n",
    "plt.title('Asteroseismic Parameters')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which ones are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badstars = ['BD+39_388','BD+43_306','HD_179959','HD_185351','HD_187217','HD_188639','HD_188875','HD_188629']\n",
    "notes = ['No secure detection','Not consistent with RG pattern','Possible contamination',r'\\citep{2017MNRAS.464.3713H}',\n",
    "         'Possible contamination or binary',r'Too difficult to get a robust \\Dnu',r'Too difficult to get a robust \\Dnu',\n",
    "         r'Too difficult to get a robust \\Dnu']\n",
    "\n",
    "notecol = [notes[j] if star in badstars else '' for j, star in enumerate(seismic['Star_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(badstars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for star in merged['Object']:\n",
    "    if star not in seismic['Star_ID']:\n",
    "        print star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for star in seismic['Star_ID']:\n",
    "    if star not in merged['Object']:\n",
    "        print star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the main catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_cat = '../data/catalogue.csv'\n",
    "cat = Table.read(fname_cat,format='ascii')\n",
    "cat.sort('kepmag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 'Clump Candidates:',oxford_join([name.replace('_',' ') for name in cat[np.array(['clump' in thing for thing in list(cat['Notes'].data.data[:])])]['Name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to get SIMBAD queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.simbad import Simbad\n",
    "from astropy import coordinates as coord\n",
    "from astropy import units as u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simbad.reset_votable_fields()\n",
    "Simbad.add_votable_fields('sptype')\n",
    "sim = Simbad.query_objects(cat['Name'])\n",
    "cat['SpType'] = sim['SP_TYPE']\n",
    "sim.write('smear_intermediate.csv')\n",
    "sim = Table.read('smear_intermediate.csv')\n",
    "c = coord.SkyCoord(ra=sim['RA'], dec=sim['DEC'],unit=(u.hourangle, u.deg), frame='icrs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = Table([Column([cc.ra.deg for cc in c],name='RA',unit='deg',description='RA'),Column([cc.dec.deg for cc in c],name='Dec',unit='deg',description='Dec')],masked=False)\n",
    "# new.write('../data/smear_simbad.csv',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the gaia tap service at http://gaia.ari.uni-heidelberg.de/tap.html for crossmatch \n",
    "using the command\n",
    "\n",
    "SELECT bj.source_id, sm.ra, sm.dec, sm.phot_g_mean_mag, bj.r_est, bj.r_lo, bj.r_hi\n",
    "FROM gaiadr2_complements.geometric_distance as bj \n",
    "JOIN TAP_UPLOAD.smear AS sm ON sm.source_id = bj.source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia = Table.read('../data/gaia_new.csv')\n",
    "gaia[gaia['source_id']==2128480311802353536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_mag(app_mag,dist):\n",
    "    return app_mag - 5.*(np.log10(dist) - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dists = Table.read('../data/dists_new.csv')\n",
    "dists.insert_row(38,\n",
    "                 vals={'source_id':2128480311802353536,'r_est':np.nan,'r_lo':np.nan,'r_hi':np.nan})\n",
    "gaia = join(dists,gaia,keys='source_id')\n",
    "\n",
    "args = np.argsort(new['RA'])\n",
    "args2 = np.argsort(args)\n",
    "gaia.sort('ra')\n",
    "gaia = gaia[args2]\n",
    "\n",
    "\n",
    "bp, rp, gg = gaia['phot_bp_mean_mag'], gaia['phot_rp_mean_mag'], gaia['phot_g_mean_mag']\n",
    "abs_gg = abs_mag(gg,dists['r_est'])\n",
    "gaia['abs_gg'] = abs_gg\n",
    "gaia['bp_rp'] = bp-rp\n",
    "abs_gg_hi = abs_mag(gg,dists['r_hi'])\n",
    "abs_gg_lo = abs_mag(gg,dists['r_lo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2083_Cyg doesn't have a parallax\n",
    "# dists.insert_row(38,\n",
    "#                  vals={'source_id':2128480311802353536,'ra':292.818076238,'dec':47.481042633,\n",
    "#                        'phot_g_mean_mag':6.81,'r_est':np.nan,'r_lo':np.nan,'r_hi':np.nan})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # check the RA/Dec are the same\n",
    "plt.plot(new['RA'],label='Input')\n",
    "plt.plot(gaia['ra'],label='Gaia')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(cat['kepmag'],gaia['phot_g_mean_mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat[np.abs(gaia['phot_g_mean_mag']-cat['kepmag'])>0.75]#.sort(np.abs(dists['phot_g_mean_mag']-cat['kepmag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaia[np.abs(gaia['phot_g_mean_mag']-cat['kepmag'])>0.75]#.sort(np.abs(dists['phot_g_mean_mag']-cat['kepmag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table(gaia['source_id']).write('sources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newcat = cat.copy()\n",
    "brightkep = Table.read('../data/Bright_Kep_new.csv')\n",
    "var = Table.read('../data/variability.csv')\n",
    "newcat = join(cat,brightkep,keys='Name')\n",
    "newcat = join(newcat,var,keys='Name')\n",
    "fname_spc = '../data/spc_giants.csv'\n",
    "# fname_spc = '../data/spc_final.txt'\n",
    "spc_data = Table.read(fname_spc,format='ascii')\n",
    "\n",
    "newcat['TRES?'] = ['TRES' if obj in spc_data['Object'] else '--' for obj in newcat['Name']]\n",
    "newcat.add_column(gaia['source_id'])\n",
    "\n",
    "newcat = join(newcat,gaia['bp_rp','source_id','r_est','r_lo','r_hi','phot_g_mean_mag'],keys='source_id',join_type=u'left')\n",
    "\n",
    "newcat.sort('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia['Name'] = [newcat['Name'][newcat['source_id']==obj][0] for obj in gaia['source_id']]\n",
    "\n",
    "gaia['TRES'] = [newcat['TRES?'][newcat['source_id']==obj][0] for obj in gaia['source_id']]\n",
    "pdg = gaia.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_spc2 = '../data/spc_giants.csv'\n",
    "spc_data2 = Table.read(fname_spc2,format='ascii')\n",
    "\n",
    "spc_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, ccat in enumerate([newcat[:52],newcat[52:]]):\n",
    "\n",
    "    newtab = Table([Column([str(obj).replace('_',' ') for obj in ccat['Name']],name='Object')])\n",
    "\n",
    "    newkeys = ['Kepler_ID','SpType','kepmag', 'phot_g_mean_mag','bp_rp','r_est','TRES?','Class']\n",
    "    names = [r'KIC',r'Spectral Type',r'$Kp$',r'$G$',r'$Bp-Rp$',r'\\gaia Distance','TRES','Variability']\n",
    "    units = ['',r'(SIMBAD)', r'(mag)','(mag)',r'(mag)','(pc)','','Class']\n",
    "    \n",
    "    translator_class = {'LPV':'LPV',\n",
    "                        'RG':'RG',\n",
    "                        'GD/DS Hybrid':r'$\\gamma\\,\\text{Dor} /\\delta\\,\\text{Sct}$',\n",
    "                        'GD':r'$\\gamma\\,\\text{Dor}$',\n",
    "                        'DS':r'$\\delta\\,\\text{Sct}$',\n",
    "                        '?':'?',\n",
    "                        '-':r'--',\n",
    "                        'Hump & Spike':'H+S',\n",
    "                        'GD/Hump & Spike':r'$\\gamma\\,\\text{Dor}$,\\,H+S',\n",
    "                        'SPB/Hump & Spike':r'SPB,\\,H+S',\n",
    "                        'EV':'EV',\n",
    "                        'EB':'EB',\n",
    "                        'SPB':'SPB',\n",
    "                        'Irregular':'Irregular',\n",
    "                        'a2cvn':r'$\\alpha^2\\,\\text{CVn}$',\n",
    "                        'RM':r'RM',\n",
    "                        'Eruptive':r'Eruptive'\n",
    "                       }\n",
    "\n",
    "    for k, key in enumerate(newkeys):\n",
    "        col = ccat[key]\n",
    "        if 'RE' in key:\n",
    "            test = Column(['\\checkmark' if 'TRES' in entry else '--' for entry in col],name=names[k])\n",
    "        elif 'bs' in key:\n",
    "            test = Column([entry.replace('under','') if 'under' in entry else 'unobserved' for entry in col],name=names[k])\n",
    "        elif 'ype' in key:\n",
    "            test = Column(['--' if np.ma.is_masked(entry) else entry for entry in col],name=names[k])\n",
    "        elif 'est' in key:\n",
    "            upcol = ccat['r_hi']\n",
    "            downcol = ccat['r_lo']\n",
    "            test = Column(['--' if 'nan' in str(col[j]) else '$%.1f^{+%.1f}_{-%.1f}$' % (col[j],upcol[j]-col[j],col[j]-downcol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "        elif key =='Class':\n",
    "            test = Column([translator_class[entry] for entry in col],name=names[k])\n",
    "        elif 'mag' in key:\n",
    "            test = Column(['%.3f' % d for d in col.data],name=names[k])\n",
    "        elif 'bp' in key:\n",
    "            test = Column(['%.3f' % d for d in col.data],name=names[k])\n",
    "        else:\n",
    "            test = Column(col.data,name=names[k])\n",
    "#         if key == 'TRES?':\n",
    "#             test = Column(['TRES' if newtab['Object'][j].replace(' ','_') in merged['Object'] else '--' for j,entry in enumerate(col)], name=names[k])\n",
    "        newtab.add_column(test)\n",
    "    \n",
    "    latexdict = ascii.latex.latexdicts['AA'].copy()\n",
    "    latexdict['tabletype']= 'table*'\n",
    "    latexdict['units'] = dict(zip(names,units))\n",
    "    if l == 0:\n",
    "        caption = r\"The full set of underobserved and unobserved stars for which new light curves have been produced in this smear catalogue. \\\n",
    "        Calibrated \\gaia distances are from \\citet{gaiadists}. \\\n",
    "        The eclipsing binary V2083~Cyg was detected by \\gaia, but a parallax could not be obtained in DR2, possibly due to binary motion.\\\n",
    "        Variability classes are determined by inspection, having their usual abbreviations. \\\n",
    "        EV denotes an ellipsoidal variable, and RM rotational modulation, though these two can appear similar. $\\alpha^2\\,\\text{CVn}$ variables are chemically-peculiar stars with rotational spot modulation,\\\n",
    "        and are noted separately from RM without chemical peculiarity.\\\n",
    "        $\\gamma\\,\\text{Dor} /\\delta\\,\\text{Sct}$ denotes a $\\gamma\\,\\text{Dor} /\\delta\\,\\text{Sct}$ hybrid, not uncertainty.\\\n",
    "        H+S denotes a `hump and spike' star.\\\n",
    "        Question marks indicate uncertainty, and dashes -- that no significant variability is observed.\" \n",
    "        caption = caption+r'\\label{all_stars}'\n",
    "        newtab.write('../paper/all_stars.tex',format='latex',latexdict=latexdict,caption=caption+'\\label{all_stars}')\n",
    "        print 'Written %s' % '../paper/all_stars.tex'\n",
    "    else:\n",
    "        latexdict['preamble'] = '\\contcaption{The full set of underobserved and unobserved stars for which new light curves have been produced in this smear catalogue. Calibrated \\gaia distances are from \\citet{gaiadists}. \\label{all_stars_cont}}'\n",
    "        newtab.write('../paper/all_stars2.tex',format='latex',latexdict=latexdict)\n",
    "        print 'Written %s' % '../paper/all_stars2.tex'\n",
    "        \n",
    "\n",
    "newtab = Table([Column([str(obj).replace('_',' ') for obj in newcat['Name']],name='Object')])\n",
    "\n",
    "newkeys = ['Kepler_ID','SpType','kepmag', 'phot_g_mean_mag','r_est','Observed', 'TRES?','Class']\n",
    "names = [r'KIC',r'Spectral Type',r'$Kp$',r'$G$',r'\\gaia Distance',r'Observed','Spectroscopy','Variability']\n",
    "units = ['',r'(SIMBAD)', r'(mag)','(mag)','(pc)','','','Class']\n",
    "\n",
    "for k, key in enumerate(newkeys):\n",
    "    col = newcat[key]\n",
    "    if 'bs' in key:\n",
    "        test = Column([entry.replace('under','') if 'under' in entry else 'unobserved' for entry in col],name=names[k])\n",
    "    elif 'ype' in key:\n",
    "        test = Column(['--' if np.ma.is_masked(entry) else entry for entry in col],name=names[k])\n",
    "    elif 'est' in key:\n",
    "        upcol = newcat['r_hi']\n",
    "        downcol = newcat['r_lo']\n",
    "        test = Column(['--' if 'nan' in str(col[j]) else '$%.1f^{+%.1f}_{-%.1f}$' % (col[j],upcol[j]-col[j],col[j]-downcol[j]) for j, x in enumerate(col)],name=names[k])\n",
    "    elif key =='Class':\n",
    "        test = Column([translator_class[entry] for entry in col],name=names[k])\n",
    "    elif 'mag' in key:\n",
    "        test = Column(['%.3f' % d for d in col.data],name=names[k])\n",
    "    elif 'bp' in key:\n",
    "        test = Column(['%.3f' % d for d in col.data],name=names[k])\n",
    "    else:\n",
    "        test = Column(col.data,name=names[k])\n",
    "#     if key == 'TRES?':\n",
    "#         test = Column(['TRES' if newtab['Object'][j].replace(' ','_') in merged['Object'] else '--' for j,entry in enumerate(col)], name=names[k])\n",
    "    newtab.add_column(test)\n",
    "\n",
    "latexdict = ascii.latex.latexdicts['AA'].copy()\n",
    "latexdict['tabletype']= 'table*'\n",
    "latexdict['units'] = dict(zip(names,units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ccat['r_est']\n",
    "upcol = ccat['r_hi']\n",
    "downcol = ccat['r_lo']\n",
    "test = Column(['--' if 'nan' in str(col[j]) else '$%.2f^{+%.2f}_{-%.2f}$' % (col[j],upcol[j]-col[j],col[j]-downcol[j]) for j, x in enumerate(col)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for_keith = newcat['Name','ra','dec']\n",
    "# for_keith.write('star_coords_keith.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now make an HR diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = dists['r_est']/((dists['r_hi']-dists['r_lo'])/2.)\n",
    "np.nanmedian(snrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorbars = np.zeros((2,np.size(abs_gg)))\n",
    "errorbars[0,:] = abs_gg_hi-abs_gg\n",
    "errorbars[1,:] = abs_gg-abs_gg_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('text', usetex=False)\n",
    "m = np.where(gaia['TRES']!='--')[0]\n",
    "plt.errorbar(bp[m]-rp[m],abs_gg[m],yerr=errorbars[:,m],fmt='.',color=colours[1],label=r'Smear Campaign (with spectra)',markersize=10)\n",
    "plt.errorbar(bp[~m]-rp[~m],abs_gg[~m],yerr=errorbars[:,~m],fmt='.',color=colours[2],label=r'Smear Campaign (no spectra)',markersize=10)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(r'$Bp-Rp$')\n",
    "plt.ylabel(r'Absolute $G$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use Megan Bedell's Gaia-Kepler crossmatch to situate these in the broader colour-magnitude diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep_data = Table.read('../data/kepler_dr2_4arcsec.fits', format='fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep_data['abs_gmag'] = kep_data['phot_g_mean_mag'] - \\\n",
    "                            5.*(np.log10(kep_data['r_est']) - 1.)\n",
    "kep_data['abs_gmag'].unit = u.mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (kep_data['phot_g_mean_mag'] <= 18.) & (kep_data['parallax'] > 0.1)\n",
    "filter = (kep_data['phot_g_mean_mag'] <= 18.) & (kep_data['parallax_over_error'] > 25)\n",
    "\n",
    "plt.scatter(kep_data['bp_rp'][filter], kep_data['abs_gmag'][filter], alpha=0.15, color='k', s=1,label='All Kepler')\n",
    "m = np.where(gaia['TRES']!='--')[0]\n",
    "plt.errorbar(bp[m]-rp[m],abs_gg[m],yerr=errorbars[:,m],fmt='.',color=colours[1],label=r'Smear + spectra',markersize=11)\n",
    "plt.errorbar(bp[~m]-rp[~m],abs_gg[~m],yerr=errorbars[:,~m],fmt='.',color=colours[2],label=r'Smear (no spectra)',markersize=11)\n",
    "\n",
    "plt.xlabel('Gaia $Bp-Rp$', fontsize=14)\n",
    "plt.ylabel(r'Absolute $G$ mag', fontsize=14)\n",
    "plt.ylim([13,-6])\n",
    "plt.xlim([-0.5,4.1])\n",
    "plt.legend()\n",
    "plt.title(r'Smear Stars in the Gaia Colour-Magnitude Diagram',y=1.01,fontsize=14)\n",
    "# plt.axvline(0.95) # separate giants and dwarfs \n",
    "plt.savefig('../paper/gaia_kepler_hr.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter = (kep_data['phot_g_mean_mag'] <= 18.) & (kep_data['parallax'] > 0.1)\n",
    "# filter = (kep_data['phot_g_mean_mag'] <= 18.) & (kep_data['parallax_over_error'] > 25)\n",
    "\n",
    "# plt.scatter(kep_data['bp_rp'][filter], kep_data['abs_gmag'][filter], alpha=0.15, color='k', s=1,label='All Kepler')\n",
    "# m = np.where(gaia['TRES']!='--')[0]\n",
    "# plt.errorbar(bp[m]-rp[m],abs_gg[m],yerr=errorbars[:,m],fmt='.',color=colours[1],label=r'Smear + spectra',markersize=10)\n",
    "# plt.errorbar(bp[~m]-rp[~m],abs_gg[~m],yerr=errorbars[:,~m],fmt='.',color=colours[2],label=r'Smear (no spectra)',markersize=10)\n",
    "\n",
    "# plt.xlabel('Gaia $Bp-Rp$', fontsize=14)\n",
    "# plt.ylabel(r'Absolute $G$ mag', fontsize=14)\n",
    "# plt.ylim([13,-6])\n",
    "# plt.xlim([-0.5,4.1])\n",
    "# plt.legend()\n",
    "# plt.title(r'Smear Stars in the Gaia Colour-Magnitude Diagram',y=1.01,fontsize=14)\n",
    "# # plt.axvline(0.95) # separate giants and dwarfs \n",
    "# plt.savefig('../paper/gaia_kepler_hr.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giants = (bp-rp>0.95)\n",
    "dwarfs = (bp-rp<0.95)\n",
    "print giants.sum(),'giants', dwarfs.sum(),'dwarfs',giants.sum()+dwarfs.sum(),'total'\n",
    "# np.savetxt('giants.txt',cat['Name'][giants])\n",
    "# np.savetxt('dwarfs.txt',cat['Name'][dwarfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find weird stars in the HR diagram\n",
    "# rc('text', usetex=False)\n",
    "# plt.errorbar(bp[dwarfs]-rp[dwarfs],abs_gg[dwarfs],yerr=errorbars[:,dwarfs],fmt='.',color=colours[2],label=r'Dwarfs',markersize=10)\n",
    "# plt.errorbar(bp[giants]-rp[giants],abs_gg[giants],yerr=errorbars[:,giants],fmt='.',color=colours[1],label=r'Giants',markersize=10)\n",
    "\n",
    "# weird = ['HD_176582', 'HD_179395']\n",
    "# for j,w in enumerate(weird):\n",
    "#     ww = np.where(gaia['Name'] == w)[0]\n",
    "#     plt.errorbar(bp[ww]-rp[ww],abs_gg[ww],yerr=errorbars[:,ww],fmt='.',color=colours[3+j],label=w,markersize=25)\n",
    "\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.xlabel(r'$Bp-Rp$')\n",
    "# plt.ylabel(r'Absolute $G$')\n",
    "# plt.legend()\n",
    "# plt.savefig('hr_weird.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Table({'Giants':cat['Name'][giants].data.data.astype('S10')})\n",
    "test.write('giants.txt',format='ascii',overwrite=True)\n",
    "\n",
    "test = Table({'dwarfs':cat['Name'][dwarfs].data.data.astype('S10')})\n",
    "test.write('dwarfs.txt',format='ascii',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compare to Hypatia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simbad.reset_votable_fields()\n",
    "Simbad.add_votable_fields('ids')\n",
    "sim = Simbad.query_objects(cat['Name'])\n",
    "ids = sim['IDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hips = []\n",
    "for eyedee in ids:\n",
    "    m = re.search('\\|HIP  (.+?)\\|',str(eyedee))\n",
    "    if m:\n",
    "        found = m.group(1)\n",
    "#     print found\n",
    "    hips.append(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinkel = Table.read('../data/hypatia-03082018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_hyp = []\n",
    "for j, hip in enumerate(hips):\n",
    "    if int(hip) in hinkel['f_hip']:\n",
    "        print hip, sim['MAIN_ID'][j]\n",
    "        in_hyp.append((hip,sim['MAIN_ID'][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import altair as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdg = gaia.to_pandas()\n",
    "pdg.assign(bprp=pdg.phot_bp_mean_mag - pdg.phot_rp_mean_mag);\n",
    "pdg.insert(len(pdg.columns), 'bprp', pd.Series(pdg.phot_bp_mean_mag - pdg.phot_rp_mean_mag, index=pdg.index))\n",
    "pdg.insert(len(pdg.columns), 'name', pd.Series(sim['MAIN_ID'], index=pdg.index))\n",
    "spec = ['TRES' if sp else 'No  Spectra' for sp in pdg['TRES']=='TRES']\n",
    "pdg.insert(len(pdg.columns), 'Spectroscopy', pd.Series(spec, index=pdg.index))\n",
    "pdg.insert(len(pdg.columns), 'SpType', pd.Series(newcat['SpType'], index=pdg.index))\n",
    "\n",
    "# pdkep = kep_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdg.Spectroscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The *Kepler* dataset is too big for Altair. But not for Bokeh - let's copy from at demo.ipynb from github.com/megbedell/gaia-kepler.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import *\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import OpenURL, Circle, HoverTool, PanTool, BoxZoomTool, ResetTool, SaveTool, TapTool, WheelZoomTool\n",
    "from bokeh.util.hex import hexbin\n",
    "from bokeh.transform import linear_cmap, factor_cmap\n",
    "from bokeh.palettes import Spectral6\n",
    "# output_notebook()\n",
    "reset_output()\n",
    "output_file(\"cmd_smear.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = (kep_data['phot_g_mean_mag'] <= 18.) & (kep_data['parallax_over_error'] > 25)\n",
    "# filter2 = (kep_data['planet?'] == 'conf') & filter1\n",
    "\n",
    "filter2 = filter1 \n",
    "\n",
    "thin = 4\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        kepid=kep_data[filter2]['kepid'].data.data[::thin],\n",
    "        kepmag=kep_data[filter2]['kepmag'].data.data[::thin],\n",
    "        bp_rp=kep_data[filter2]['bp_rp'].data.data[::thin],\n",
    "        abs_gmag=kep_data[filter2]['abs_gmag'].data.data[::thin],\n",
    "        mass=kep_data[filter2]['mass'].data.data[::thin],\n",
    "        radius=kep_data[filter2]['radius'].data.data[::thin]\n",
    "        )\n",
    "    )\n",
    "\n",
    "source_smear = ColumnDataSource(\n",
    "    data=dict(\n",
    "        name=pdg.name.values,\n",
    "        abs_gmag=pdg.abs_gg.values,\n",
    "        bp_rp=pdg.bprp.values,\n",
    "        spec=pdg.Spectroscopy.values,\n",
    "        sptype=pdg.SpType.values\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(\n",
    "#         name=pdg.name.values,\n",
    "#         abs_gmag=pdg.abs_gg.values,\n",
    "#         bp_rp=pdg.bprp.values,\n",
    "#         spec=pdg.Spectroscopy.values,\n",
    "#         sptype=pdg.SpType.values\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xrange = (-0.5,4.1)\n",
    "yrange = (13,-6)\n",
    "\n",
    "fig = figure(tools=\"wheel_zoom,pan,reset\",x_range=xrange,\n",
    "        y_range=yrange,title=\"Smear Stars in the Gaia Colour-Magnitude Diagram\")   \n",
    "kep_render = fig.circle('bp_rp','abs_gmag', source=source, size=4, name='KICs',color='black',alpha=0.2)\n",
    "\n",
    "smear_render = fig.circle('bp_rp','abs_gmag', source=source_smear, size=10, name='Smear',\n",
    "                          color=factor_cmap('spec',palette=Spectral6,factors=pdg.Spectroscopy.values),legend='spec')\n",
    "hover = HoverTool(renderers=[smear_render],\n",
    "                    tooltips=[\n",
    "        (\"Name\", \"@name\"),\n",
    "        (\"Sp. Type\",\"@sptype\"),\n",
    "        (\"Abs. G mag\",\"@abs_gmag\"),\n",
    "        (\"Bp-Rp\",\"@bp_rp\")\n",
    "                            ]\n",
    "    )\n",
    "fig.add_tools(hover)\n",
    "fig.legend.orientation = \"vertical\"\n",
    "fig.legend.location = \"bottom_left\"\n",
    "\n",
    "fig.xaxis.axis_label = 'Gaia Bp-Rp (mag)'\n",
    "fig.yaxis.axis_label = 'Gaia Abs. G Mag'\n",
    "fig.xaxis.axis_label_text_font_size = '14pt'\n",
    "fig.xaxis.major_label_text_font_size = '12pt'\n",
    "fig.yaxis.axis_label_text_font_size = '14pt'   \n",
    "fig.yaxis.major_label_text_font_size = '12pt' \n",
    "save(fig)\n",
    "# show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j, star in enumerate(pdg.name.values):\n",
    "#     print j, star, pdg.abs_gg.values[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if Hipparcos parallaxes differ from Gaia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simbad.reset_votable_fields()\n",
    "Simbad.add_votable_fields('parallax')\n",
    "sim = Simbad.query_objects(cat['Name'])\n",
    "hip_par = sim['PLX_VALUE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.esasky import ESASky\n",
    "esasky = ESASky()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hippar = []\n",
    "for j, hip in enumerate(hips):\n",
    "    print j, hip\n",
    "    dummy = esasky.query_object_catalogs('HIP'+str(hip),catalogs='HIPPARCOS-2')[0]\n",
    "    hippar.append(dummy['plx'].data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallaxes_hip = np.array(hippar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gaia['phot_g_mean_mag'],gaia['parallax']/parallaxes_hip,'.',markersize=12,label='Gaia/Hipparcos')\n",
    "plt.axhline(1.,color=colours[1],label='1')\n",
    "plt.legend()\n",
    "plt.xlabel(r'Gaia $G$ mag')\n",
    "plt.ylabel('Parallax Ratio')\n",
    "plt.title('Comparison of Gaia and Hipparcos Parallaxes',y=1.01)\n",
    "plt.savefig('gaiavship.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gaia['parallax'],parallaxes_hip,'.')\n",
    "plt.plot(gaia['parallax'],gaia['parallax'],'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gaia['parallax']/parallaxes_hip,bins=20);\n",
    "plt.axvline(1,color=colours[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's check everything against the Bright_Kep overall bright kepler catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "brightkep = Table.read('../data/Bright_Kep_new.csv')\n",
    "# reload(sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightkep.sort('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = join(cat,brightkep,keys='Name')\n",
    "test.sort('Name')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdcat, pdbr = cat.to_pandas(), brightkep.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdcat.join(pdbr,on='Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = (glob.glob(\"../data/lcs/*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = glob.glob(\"../data/lcs/V543_Lyr_smear_combined.csv\")\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cat['Name']:\n",
    "    test = glob.glob(\"../data/lcs/%s_smear_combined.csv\" % name)\n",
    "#     print name, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brightkep['Kepler_ID'].pprint(max_lines=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_in = []\n",
    "for name in cat['Name']:\n",
    "    if name not in brightkep['Name']:\n",
    "        print name\n",
    "        names_in.append(name)\n",
    "        \n",
    "print len(names_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brightkep['Name'].pprint(max_lines=230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load stellar variability classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = Table.read('../data/variability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cat['Name']:\n",
    "    if name not in var['Name']:\n",
    "        print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcat[newcat['Name']=='BD+42_3150']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apogee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_apogee = '../data/Pope_APOGEEDR14.fits'\n",
    "apogee = Table.read(fname_apogee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, name in enumerate(apogee['Name']):\n",
    "    apogee['Name'][j] = name.replace(' ','')\n",
    "apogee['Object']=apogee['Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apogee_seismic = join(apogee,astero_logg,keys='Object')\n",
    "apogee_seismic['Object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apogee_var = join(apogee,var,keys='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apogee_var['Name','Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Venn diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2, venn3, venn3_circles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic_names = set(seismic['Star_ID'])\n",
    "# seismic_names.remove('HD_189636')\n",
    "# seismic_names.add('HD_189636A') # typo star make A\n",
    "spec_names = set(spc_data['Object'][spc_data['Object']!='HD_176466']) # typo star remove\n",
    "all_names = set(newcat['Name'])\n",
    "# giants_names = set(cat['Name'][giants].data.data.astype('S10'))\n",
    "# dwarf_names = set(cat['Name'][dwarfs].data.data.astype('S10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_by_id(label, ID):\n",
    "    num = v.get_label_by_id(ID).get_text() \n",
    "    v.get_label_by_id(ID).set_text(label+\"\\n\"+num)\n",
    "\n",
    "\n",
    "labels = ('Asteroseismology','Spectroscopy','All Stars')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = venn3([seismic_names,spec_names,all_names],set_labels=labels,alpha=0.2)\n",
    "lbl = v.get_label_by_id('001')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x, y-0.1))  # Or whatever\n",
    "lbl = v.get_label_by_id('111')\n",
    "x, y = lbl.get_position()\n",
    "lbl.set_position((x-0.3, y))  # Or whatever\n",
    "\n",
    "\n",
    "venn3_circles([seismic_names,spec_names,all_names],linewidth=0.5);\n",
    "plt.savefig('../paper/venn.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in spec_names:\n",
    "    if name not in all_names:\n",
    "        print 'Spectroscopy:',name,'not in main catalogue'\n",
    "\n",
    "for name in seismic_names:\n",
    "    if name not in all_names:\n",
    "        print 'Asteroseismology:',name,'not in main catalogue'\n",
    "        \n",
    "for name in seismic_names:\n",
    "    if name not in spec_names:\n",
    "        print 'Asteroseismic data available for',name,'but not spectroscopy'\n",
    "        \n",
    "for name in diff['Object']:\n",
    "    if name not in seismic_names:\n",
    "#         print 'Abundances data available for',name,'but not asteroseismology'\n",
    "        print name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic[seismic['Star_ID']=='HD_189636']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_data['SNRe'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
